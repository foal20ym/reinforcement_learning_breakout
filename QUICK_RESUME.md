# âš¡ Quick Start: Resume Your Training

## Your Situation

âœ… You stopped training at **episode 7200**
âœ… Latest checkpoint: `checkpoints/dqn_breakout_episode_7200.pt`
âœ… Resume functionality is now available!

## Option 1: Resume with Default Speed (Stable)

```bash
cd /home/joel/Civ_Data/RL/Project/reinforcement_learning_breakout
python main.py --train
```

When prompted, press **Enter** to resume from episode 7200.

## Option 2: Resume with Fast Training (Recommended)

### Step 1: Switch to fast config

Edit `train.py` line 13:
```python
# Change from:
from utils import config_breakout as config
# To:
from utils import config_fast as config
```

Or use this command:
```bash
cd /home/joel/Civ_Data/RL/Project/reinforcement_learning_breakout
sed -i 's/config_breakout/config_fast/' train.py
```

### Step 2: Resume training
```bash
python main.py --resume latest
```

**Benefits of fast config:**
- 30-40% faster training
- Larger batch size (64 vs 32) â†’ better GPU usage
- Start learning sooner
- Slightly more aggressive exploration decay

## What You'll See

```
Creating environment: ALE/Breakout-v5
Number of actions: 4
Observation space: (4, 84, 84)
Using device: cuda

============================================================
Resuming training from checkpoint: checkpoints/dqn_breakout_episode_7200.pt
Checkpoint loaded from checkpoints/dqn_breakout_episode_7200.pt
Starting from episode 7201, step XXXXX
Current epsilon: 0.XXXX
============================================================

Loaded previous training statistics (7200 episodes)

Episode 7210 | Reward: 15.00 | Avg(100): 12.50 | Length: 890 | Epsilon: 0.145
...
```

## Speed Comparison for Your Remaining Training

You have ~2800 episodes remaining (7200 â†’ 10000).

| Config           | Estimated Time (GPU) | Estimated Time (CPU) |
| ---------------- | -------------------- | -------------------- |
| Default          | ~56-70 hours         | ~280-560 hours       |
| Fast             | ~39-50 hours         | ~233-390 hours       |
| Fast + Optimized | ~35-45 hours         | ~200-350 hours       |

*Based on RTX 3060 / mid-range CPU*

## Recommended: Fast Config Changes

The fast config changes these parameters safely:

```python
# Speed improvements:
BATCH_SIZE = 64              # Was 32 - Better GPU utilization
MIN_REPLAY_SIZE = 5000       # Was 10000 - Start learning sooner
EPS_DECAY_STEPS = 750000     # Was 1000000 - Faster exploitation
LEARNING_RATE = 0.0003       # Was 0.00025 - Slightly faster learning
```

All changes are **safe** and won't hurt your agent's performance!

## Additional Speed Boost (Optional)

### Enable Model Compilation (PyTorch 2.0+)

Check your PyTorch version:
```bash
python -c "import torch; print(torch.__version__)"
```

If you have 2.0+, add to `core/agent.py` after line 28:

```python
# After: self.target_net.eval()
# Add:
try:
    self.policy_net = torch.compile(self.policy_net)
    self.target_net = torch.compile(self.target_net)
    print("âœ“ Model compilation enabled")
except:
    print("! Model compilation not available")
```

**Extra speedup:** ~10-20%

## Monitor Your Training

### Check progress:
```bash
# View training plot
eog logs/training_plot.png

# Check latest rewards
tail logs/training_stats.npz
```

### GPU usage:
```bash
# In another terminal
watch -n 1 nvidia-smi
```

You want to see:
- **GPU Utilization**: 70-95%
- **Memory Usage**: As high as possible without OOM

If GPU usage is low, increase `BATCH_SIZE` to 128 or 256.

## Quick Commands

```bash
# Resume (auto-detect, with prompt)
python main.py --train

# Resume (no prompt)
python main.py --resume latest

# Evaluate current checkpoint
python main.py --evaluate --checkpoint checkpoints/dqn_breakout_episode_7200.pt

# Start fresh (if needed)
python main.py --fresh
```

## Expected Performance at Episode 7200

You should be seeing:
- Average reward: 20-50 (depending on training)
- Episode length: 800-1500 steps
- Epsilon: ~0.10-0.28 (depending on config)
- Consistent brick breaking behavior

By episode 10000, expect:
- Average reward: 40-100+
- Episode length: 1000-2000 steps
- Strong strategic play

## Summary

âœ… **For stable training:** Use default config, resume normally
âš¡ **For faster training:** Switch to `config_fast`, resume with `--resume latest`

Both are safe - the fast config just trains 30-40% quicker! ðŸš€
